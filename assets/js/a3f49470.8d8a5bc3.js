"use strict";(self.webpackChunkopen_assistant=self.webpackChunkopen_assistant||[]).push([[4168],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>h});var n=a(67294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function s(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?s(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},s=Object.keys(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var l=n.createContext({}),p=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},d=function(e){var t=p(e.components);return n.createElement(l.Provider,{value:t},e.children)},u="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,s=e.originalType,l=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),u=p(a),m=o,h=u["".concat(l,".").concat(m)]||u[m]||c[m]||s;return a?n.createElement(h,r(r({ref:t},d),{},{components:a})):n.createElement(h,r({ref:t},d))}));function h(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var s=a.length,r=new Array(s);r[0]=m;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[u]="string"==typeof e?e:o,r[1]=i;for(var p=2;p<s;p++)r[p]=a[p];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},95117:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>c,frontMatter:()=>s,metadata:()=>i,toc:()=>p});var n=a(87462),o=(a(67294),a(3905));const s={},r="Datasets",i={unversionedId:"data/datasets",id:"data/datasets",title:"Datasets",description:"The datasets for this project are currently hosted as loading scripts on the",source:"@site/docs/data/datasets.md",sourceDirName:"data",slug:"/data/datasets",permalink:"/Open-Assistant/docs/data/datasets",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Data Schemas",permalink:"/Open-Assistant/docs/data/schemas"},next:{title:"Data Augmentation",permalink:"/Open-Assistant/docs/data/augmentation"}},l={},p=[{value:"Adding a new dataset",id:"adding-a-new-dataset",level:2},{value:"0. Pre-Requisites",id:"0-pre-requisites",level:3},{value:"1. <strong>Fork the OpenAssistant repository</strong>",id:"1-fork-the-openassistant-repository",level:3},{value:"2. <strong>Create a development environment</strong>",id:"2-create-a-development-environment",level:3},{value:"2a) Create a conda environment",id:"2a-create-a-conda-environment",level:4},{value:"2b) Create a venv environment",id:"2b-create-a-venv-environment",level:4},{value:"3. Prepare a folder in <code>datasets</code> for your dataloader",id:"3-prepare-a-folder-in-datasets-for-your-dataloader",level:3},{value:"(Optional) Prepare local dataset files",id:"optional-prepare-local-dataset-files",level:4},{value:"4. Implement your dataset",id:"4-implement-your-dataset",level:3},{value:"Example scripts",id:"example-scripts",level:4},{value:"Running &amp; debugging",id:"running--debugging",level:4},{value:"5. Check if your dataloader works",id:"5-check-if-your-dataloader-works",level:3},{value:"6. Create a dataset card",id:"6-create-a-dataset-card",level:3},{value:"7. Format your code",id:"7-format-your-code",level:3},{value:"8. Commit your changes",id:"8-commit-your-changes",level:3},{value:"9. <strong>Make a pull request</strong>",id:"9-make-a-pull-request",level:3},{value:"Admins Uploading a dataset to the Hugging Face Hub",id:"admins-uploading-a-dataset-to-the-hugging-face-hub",level:2},{value:"1. Setup",id:"1-setup",level:3},{value:"2. Create a new dataset repository",id:"2-create-a-new-dataset-repository",level:3},{value:"3. Copy a dataset loading script and dataset card",id:"3-copy-a-dataset-loading-script-and-dataset-card",level:3},{value:"(Optional) Prepare local dataset files",id:"optional-prepare-local-dataset-files-1",level:4},{value:"4. Upload to the Hub",id:"4-upload-to-the-hub",level:3}],d={toc:p},u="wrapper";function c(e){let{components:t,...a}=e;return(0,o.kt)(u,(0,n.Z)({},d,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"datasets"},"Datasets"),(0,o.kt)("p",null,"The datasets for this project are currently hosted as loading scripts on the\n",(0,o.kt)("a",{parentName:"p",href:"https://huggingface.co/OpenAssistant"},"Open-Assistant organization")," the Hugging\nFace Hub. Each of them can be loaded by first installing the \ud83e\udd17 Datasets\nlibrary:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"python -m pip install datasets\n")),(0,o.kt)("p",null,"and then running:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from datasets import load_dataset\n\ndataset = load_dataset("OpenAssistant/{dataset-name}")\n')),(0,o.kt)("p",null,"We use this GitHub repository to accept new submissions and standardize quality\ncontrol. See the instructions below if you'd like to contribute a new dataset to\nthe project."),(0,o.kt)("h2",{id:"adding-a-new-dataset"},"Adding a new dataset"),(0,o.kt)("h3",{id:"0-pre-requisites"},"0. Pre-Requisites"),(0,o.kt)("p",null,"Install Git and create a GitHub account prior to implementing a dataset; you can\nfollow instructions to install Git\n",(0,o.kt)("a",{parentName:"p",href:"https://git-scm.com/book/en/v2/Getting-Started-Installing-Git"},"here"),"."),(0,o.kt)("p",null,"You will also need at least Python 3.8+. If you are installing Python, we\nrecommend downloading\n",(0,o.kt)("a",{parentName:"p",href:"https://docs.anaconda.com/anaconda/install/index.html"},"Anaconda")," to curate a\npython environment with necessary packages. ",(0,o.kt)("strong",{parentName:"p"},"We strongly recommend Python 3.8+\nfor stability"),"."),(0,o.kt)("h3",{id:"1-fork-the-openassistant-repository"},"1. ",(0,o.kt)("strong",{parentName:"h3"},"Fork the OpenAssistant repository")),(0,o.kt)("p",null,"Fork the ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/LAION-AI/Open-Assistant"},"OpenAssistant repository"),'.\nTo do this, click the link to the repository and click "Fork" in the upper-right\ncorner. You should get an option to fork to your account, provided you are\nsigned into Github.'),(0,o.kt)("p",null,"After you fork, clone the repository locally. You can do so as follows:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"git clone git@github.com:<your_github_username>/Open-Assistant.git\ncd Open-Assistant  # enter the directory\n")),(0,o.kt)("p",null,"Next, you want to set your ",(0,o.kt)("inlineCode",{parentName:"p"},"upstream")," location to enable you to push/pull (add\nor receive updates). You can do so as follows:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"git remote add upstream git@github.com:LAION-AI/Open-Assistant.git\n")),(0,o.kt)("p",null,"You can optionally check that this was set properly by running the following\ncommand:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"git remote -v\n")),(0,o.kt)("p",null,"The output of this command should look as follows:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"origin  git@github.com:<your_github_username>/Open-Assistant.git (fetch)\norigin  git@github.com:<your_github_username>/Open-Assistant.git (push)\nupstream        git@github.com:LAION-AI/Open-Assistant.git (fetch)\nupstream        git@github.com:LAION-AI/Open-Assistant.git (push)\n")),(0,o.kt)("p",null,"If you do NOT have an ",(0,o.kt)("inlineCode",{parentName:"p"},"origin")," for whatever reason, then run:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"git remote add origin git@github.com:<your_github_username>/Open-Assistant.git\n")),(0,o.kt)("p",null,"The goal of ",(0,o.kt)("inlineCode",{parentName:"p"},"upstream")," is to keep your repository up-to-date to any changes that\nare made officially to the OpenAssistant repo. You can do this as follows by\nrunning the following commands:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"git fetch upstream\ngit pull\n")),(0,o.kt)("p",null,"Provided you have no ",(0,o.kt)("em",{parentName:"p"},"merge conflicts"),", this will ensure the repo stays\nup-to-date as you make changes. However, before you make changes, you should\nmake a custom branch to implement your changes."),(0,o.kt)("p",null,"You can make a new branch as such:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"git checkout -b <dataset_name>\n")),(0,o.kt)("admonition",{type:"caution"},(0,o.kt)("p",{parentName:"admonition"},"Please do not make changes on the main branch!")),(0,o.kt)("p",null,"Always make sure you're on the right branch with the following command:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"git branch\n")),(0,o.kt)("p",null,"The correct branch will have a asterisk ","*"," in front of it."),(0,o.kt)("h3",{id:"2-create-a-development-environment"},"2. ",(0,o.kt)("strong",{parentName:"h3"},"Create a development environment")),(0,o.kt)("p",null,"You can make an environment in any way you choose. We highlight two possible\noptions:"),(0,o.kt)("h4",{id:"2a-create-a-conda-environment"},"2a) Create a conda environment"),(0,o.kt)("p",null,"The following instructions will create an Anaconda ",(0,o.kt)("inlineCode",{parentName:"p"},"openassistant")," environment."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Install ",(0,o.kt)("a",{parentName:"li",href:"https://docs.anaconda.com/anaconda/install/"},"anaconda")," for your\nappropriate operating system."),(0,o.kt)("li",{parentName:"ul"},"Run the following command while in the ",(0,o.kt)("inlineCode",{parentName:"li"},"biomedical")," folder (you can pick your\npython version):")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"conda create -n openassistant python=3.8  # Creates a conda env\nconda activate openassistant  # Activate your conda environment\ncd openassistant\npip install -r dev-requirements.txt # Install this while in the openassistant folder\n")),(0,o.kt)("p",null,"You can deactivate your environment at any time by either exiting your terminal\nor using ",(0,o.kt)("inlineCode",{parentName:"p"},"conda deactivate"),"."),(0,o.kt)("h4",{id:"2b-create-a-venv-environment"},"2b) Create a venv environment"),(0,o.kt)("p",null,"Python 3.3+ has venv automatically installed; official information is found\n",(0,o.kt)("a",{parentName:"p",href:"https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/"},"here"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"python3 -m venv <your_env_name_here>\nsource <your_env_name_here>/bin/activate  # activate environment\ncd openassistant\npip install -r dev-requirements.txt # Install this while in the openassistant folder\n")),(0,o.kt)("p",null,"Make sure your ",(0,o.kt)("inlineCode",{parentName:"p"},"pip")," package points to your environment's source."),(0,o.kt)("h3",{id:"3-prepare-a-folder-in-datasets-for-your-dataloader"},"3. Prepare a folder in ",(0,o.kt)("inlineCode",{parentName:"h3"},"datasets")," for your dataloader"),(0,o.kt)("p",null,"Make a new directory within the ",(0,o.kt)("inlineCode",{parentName:"p"},"openassistant/datasets")," directory:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"mkdir openassistant/datasets/<dataset_name>\n")),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"NOTE"),": Please use snake_case, i.e. lowercase letters and underscores when\nchoosing a ",(0,o.kt)("inlineCode",{parentName:"p"},"<dataset_name>"),"."),(0,o.kt)("p",null,"Add an ",(0,o.kt)("inlineCode",{parentName:"p"},"__init__.py")," file to this directory:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"touch openassistant/datasets/<dataset_name>/__init__.py\n")),(0,o.kt)("p",null,"Next, copy the ",(0,o.kt)("inlineCode",{parentName:"p"},"template.py")," script and ",(0,o.kt)("inlineCode",{parentName:"p"},"hub.py")," module of ",(0,o.kt)("inlineCode",{parentName:"p"},"templates")," into your\ndataset folder. The ",(0,o.kt)("inlineCode",{parentName:"p"},"template.py"),' script has "TODOs" to fill in for your\ndataloading script:'),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"cp templates/hub.py openassistant/datasets/<dataset_name>/\ncp templates/template.py openassistant/datasets/<dataset_name>/<dataset_name>.py\n")),(0,o.kt)("h4",{id:"optional-prepare-local-dataset-files"},"(Optional) Prepare local dataset files"),(0,o.kt)("p",null,"If your dataset files aren't publicly available via URLs (e.g. because you\nimplemented a web scraper), you'll need to implement some extra logic to store\nand prepare the data locally prior to implementing a loading script in \ud83e\udd17\nDatasets."),(0,o.kt)("p",null,"To do so, first copy the template script for dataset creation:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"cp templates/prepare.py openassistant/datasets/<dataset_name>/\n")),(0,o.kt)("p",null,"Next, implement any logic that is needed to prepare a local version of the\ndataset files (by convention we store them in ",(0,o.kt)("inlineCode",{parentName:"p"},"datasets/<dataset_name>/data/"),").\nAdd any extra dependencies to a ",(0,o.kt)("inlineCode",{parentName:"p"},"requirements.txt")," file and provide instructions\non how to prepare the dataset files in a README:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"touch openassistant/datasets/<dataset_name>/requirements.txt\ncp templates/README.py openassistant/datasets/<dataset_name>/\n")),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Note:")," Do not commit any dataset files to the OpenAssistant repo - all data\nwill be hosted on the Hugging Face Hub. This step is needed for the project's\ndata admins to be able to replicate the dataset creation process before pushing\nto the Hub."),(0,o.kt)("h3",{id:"4-implement-your-dataset"},"4. Implement your dataset"),(0,o.kt)("p",null,"To implement your dataloader, you will need to follow ",(0,o.kt)("inlineCode",{parentName:"p"},"template.py")," and fill in\nall necessary TODOs. There are three key methods that are important:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"_info"),": Specifies the schema of the expected dataloader"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"_split_generators"),": Downloads and extracts data for each split (e.g.\ntrain/val/test) or associate local data with each split."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"_generate_examples"),": Create examples from data that conform to each schema\ndefined in ",(0,o.kt)("inlineCode",{parentName:"li"},"_info"),".")),(0,o.kt)("p",null,"For the ",(0,o.kt)("inlineCode",{parentName:"p"},"_info_")," function, you will need to define ",(0,o.kt)("inlineCode",{parentName:"p"},"features")," for your\n",(0,o.kt)("inlineCode",{parentName:"p"},"DatasetInfo")," object. For each dataset config, choose the right schema from our\nlist of examples. You can find the schemas in the\n",(0,o.kt)("a",{parentName:"p",href:"https://github.com/LAION-AI/Open-Assistant/tree/main/openassistant"},"schemas directory"),"."),(0,o.kt)("p",null,"You will use this schema in the ",(0,o.kt)("inlineCode",{parentName:"p"},"_generate_examples")," return value."),(0,o.kt)("p",null,"Populate the information in the dataset according to this schema; some fields\nmay be empty."),(0,o.kt)("h4",{id:"example-scripts"},"Example scripts"),(0,o.kt)("p",null,"TODO"),(0,o.kt)("h4",{id:"running--debugging"},"Running & debugging"),(0,o.kt)("p",null,"You can run your data loader script during development by appending the\nfollowing statement to your code\n(",(0,o.kt)("a",{parentName:"p",href:"https://github.com/LAION-AI/Open-Assistant/blob/main/openassistant/templates/template.py"},"templates/template.py"),"\nalready includes this):"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'if __name__ == "__main__":\n    datasets.load_dataset(__file__)\n')),(0,o.kt)("p",null,"If you want to use an interactive debugger during development, you will have to\nuse ",(0,o.kt)("inlineCode",{parentName:"p"},"breakpoint()")," instead of setting breakpoints directly in your IDE. Most\nIDEs will recognize the ",(0,o.kt)("inlineCode",{parentName:"p"},"breakpoint()")," statement and pause there during\ndebugging. If your preferred IDE doesn't support this, you can always run the\nscript in your terminal and debug with ",(0,o.kt)("inlineCode",{parentName:"p"},"pdb"),"."),(0,o.kt)("h3",{id:"5-check-if-your-dataloader-works"},"5. Check if your dataloader works"),(0,o.kt)("p",null,"Make sure your dataset is implemented correctly by checking in python the\nfollowing commands:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from datasets import load_dataset\n\ndata = load_dataset("openassistant/datasets/<dataset_name>/<dataset_name>.py", name="<dataset_name>_<schema>")\n')),(0,o.kt)("p",null,"Run these commands from the top level of the ",(0,o.kt)("inlineCode",{parentName:"p"},"OpenAssistant")," repo."),(0,o.kt)("h3",{id:"6-create-a-dataset-card"},"6. Create a dataset card"),(0,o.kt)("p",null,"Copy and fill out the template dataset card:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"cp templates/dataset_card.md openassistant/datasets/<dataset_name>/README.md\n")),(0,o.kt)("h3",{id:"7-format-your-code"},"7. Format your code"),(0,o.kt)("p",null,"From the main directory, run the code quality checks via the following command:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"pre-commit run --all-files\n")),(0,o.kt)("p",null,"This runs the black formatter, isort, and lints to ensure that the code is\nreadable and looks nice. Flake8 linting errors may require manual changes."),(0,o.kt)("h3",{id:"8-commit-your-changes"},"8. Commit your changes"),(0,o.kt)("p",null,'First, commit your changes to the branch to "add" the work:'),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'git add openassistant/datasets/<dataset_name>/*.py\ngit commit -m "A message describing your commits"\n')),(0,o.kt)("p",null,"Then, run the following commands to incorporate any new changes in the master\nbranch of datasets as follows:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"git fetch upstream\ngit rebase upstream/main\n")),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Run these commands in your custom branch"),"."),(0,o.kt)("p",null,"Push these changes to ",(0,o.kt)("strong",{parentName:"p"},"your fork")," with the following command:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"git push -u origin <dataset_name>\n")),(0,o.kt)("h3",{id:"9-make-a-pull-request"},"9. ",(0,o.kt)("strong",{parentName:"h3"},"Make a pull request")),(0,o.kt)("p",null,"Make a Pull Request to implement your changes on the main repository\n",(0,o.kt)("a",{parentName:"p",href:"https://github.com/LAION-AI/Open-Assistant/pulls"},"here"),'. To do so, click "New\nPull Request". Then, choose your branch from your fork to push into "base:main".'),(0,o.kt)("p",null,"When opening a PR, please link the\n",(0,o.kt)("a",{parentName:"p",href:"https://github.com/LAION-AI/Open-Assistant/issues"},"issue")," corresponding to your\ndataset using\n",(0,o.kt)("a",{parentName:"p",href:"https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue"},"closing keywords"),"\nin the PR's description, e.g. ",(0,o.kt)("inlineCode",{parentName:"p"},"resolves #17"),"."),(0,o.kt)("h2",{id:"admins-uploading-a-dataset-to-the-hugging-face-hub"},"[Admins]"," Uploading a dataset to the Hugging Face Hub"),(0,o.kt)("p",null,"Uploading a new dataset from ",(0,o.kt)("inlineCode",{parentName:"p"},"openassistant/datasets/<dataset_name>")," to the\nHugging Face Hub typically involves the following steps:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Setup"),(0,o.kt)("li",{parentName:"ol"},"Create a new dataset repository"),(0,o.kt)("li",{parentName:"ol"},"Copy a dataset loading script and dataset card"),(0,o.kt)("li",{parentName:"ol"},"Upload to the Hub")),(0,o.kt)("h3",{id:"1-setup"},"1. Setup"),(0,o.kt)("p",null,"To upload a dataset to the OpenAssistant organization, you first need to:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Create a ",(0,o.kt)("a",{parentName:"li",href:"https://huggingface.co/join"},"Hugging Face account")," (it's free)"),(0,o.kt)("li",{parentName:"ul"},"Join the ",(0,o.kt)("a",{parentName:"li",href:"https://huggingface.co/OpenAssistant"},"OpenAssistant organization")," by\nclicking on the ",(0,o.kt)("em",{parentName:"li"},"Request to join this org")," button on the top right-hand side")),(0,o.kt)("p",null,"Next, check that you're correctly logged in and that ",(0,o.kt)("inlineCode",{parentName:"p"},"git-lfs")," is installed so\nthat the dataset can be uploaded. To log in, create a ",(0,o.kt)("strong",{parentName:"p"},"write access token"),"\nthat can be found under your Hugging Face profile (icon in the top right corner\non ",(0,o.kt)("a",{parentName:"p",href:"http://hf.co/"},"hf.co"),", then Settings -> Access Tokens -> User Access Tokens\n-> New Token. Alternatively, you can go to\n",(0,o.kt)("a",{parentName:"p",href:"https://huggingface.co/settings/tokens"},"your token settings")," directly."),(0,o.kt)("p",null,"Once you've created a token, run:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"huggingface-cli login\n")),(0,o.kt)("p",null,"in a terminal, or case you're working in a notebook"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"from huggingface_hub import notebook_login\n\nnotebook_login()\n")),(0,o.kt)("p",null,"You can then copy-paste your token to log in locally."),(0,o.kt)("p",null,"Next, let's make sure that ",(0,o.kt)("inlineCode",{parentName:"p"},"git-lfs")," is correctly installed. To do so, simply\nrun:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"git-lfs -v\n")),(0,o.kt)("p",null,"The output should show something like\n",(0,o.kt)("inlineCode",{parentName:"p"},"git-lfs/2.13.2 (GitHub; linux amd64; go 1.15.4)"),". If your console states that\nthe ",(0,o.kt)("inlineCode",{parentName:"p"},"git-lfs")," command was not found, please make sure to install it\n",(0,o.kt)("a",{parentName:"p",href:"https://git-lfs.github.com/"},"here")," or simply via:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'sudo apt-get install git-lfs\ngit config --global user.email "you@example.com"\ngit config --global user.name "Your Name"\n')),(0,o.kt)("p",null,"The final step of the setup is to install the \ud83e\udd17 Datasets library by running:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"python -m pip install datasets\n")),(0,o.kt)("h3",{id:"2-create-a-new-dataset-repository"},"2. Create a new dataset repository"),(0,o.kt)("p",null,"Follow ",(0,o.kt)("a",{parentName:"p",href:"https://huggingface.co/docs/datasets/upload_dataset"},"this guide")," for\ninstructions on creating a new dataset repo on the Hub. Use the same snake_case\nname as the dataset in ",(0,o.kt)("inlineCode",{parentName:"p"},"openassistant/datasets/<dataset_name>"),"."),(0,o.kt)("p",null,"Once you've created the dataset repo, clone it by running:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"git clone https://huggingface.co/datasets/OpenAssistant/<dataset_name>\ncd <dataset_name>\n")),(0,o.kt)("h3",{id:"3-copy-a-dataset-loading-script-and-dataset-card"},"3. Copy a dataset loading script and dataset card"),(0,o.kt)("p",null,"Next, copy the loading script and dataset card to your repo:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"cp openassistant/datasets/<dataset_name>/<dataset_name>.py .\ncp openassistant/datasets/<dataset_name>/README.md .\n")),(0,o.kt)("h4",{id:"optional-prepare-local-dataset-files-1"},"(Optional) Prepare local dataset files"),(0,o.kt)("p",null,"If the dataset files of ",(0,o.kt)("inlineCode",{parentName:"p"},"openassistant/datasets/<dataset_name>")," aren't public,\nyou'll need to run the ",(0,o.kt)("inlineCode",{parentName:"p"},"openassistant/datasets/<dataset_name>/prepare.py")," script\nto create them. Store them in the same directory that is specified by the\nloading script (",(0,o.kt)("inlineCode",{parentName:"p"},"data")," by default)."),(0,o.kt)("h3",{id:"4-upload-to-the-hub"},"4. Upload to the Hub"),(0,o.kt)("p",null,"Once the dataset script and card are ready, use Git to push them to the Hub\n(along with any data files you may need)."),(0,o.kt)("p",null,"At this point, you can load the dataset by running:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from datasets import load_dataset\n\nload_dataset("OpenAssistant/{dataset_name}")\n')),(0,o.kt)("p",null,"Congratulations - you've now added a dataset to the OpenAssistant org!"))}c.isMDXComponent=!0}}]);